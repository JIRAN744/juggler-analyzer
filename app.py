"""
ğŸ° ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼ ãƒ›ãƒ¼ãƒ«å‚¾å‘åˆ†æãƒ„ãƒ¼ãƒ«
â€» Seleniumä¸è¦ â€” requests + BeautifulSoup ã®ã¿
"""
import streamlit as st
import pandas as pd
import numpy as np
from scipy.stats import binom
from bs4 import BeautifulSoup
import requests
import time
from datetime import datetime
from urllib.parse import urlparse, parse_qs, unquote
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

# â”€â”€ æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆ â”€â”€
try:
    import japanize_matplotlib
except Exception:
    import matplotlib.font_manager as fm
    _jp = [f.name for f in fm.fontManager.ttflist
           if any(k in f.name.lower() for k in
                  ["gothic","meiryo","yu ","ipaex","noto sans cjk","hiragino"])]
    if _jp:
        plt.rcParams["font.family"] = _jp[0]
    plt.rcParams["axes.unicode_minus"] = False

warnings.filterwarnings("ignore")
sns.set_palette("husl")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒšãƒ¼ã‚¸è¨­å®š
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.set_page_config(
    page_title="ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼ ãƒ›ãƒ¼ãƒ«å‚¾å‘åˆ†æãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ°",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.markdown("""
<style>
.hero{background:linear-gradient(135deg,#e74c3c 0%,#c0392b 50%,#8e44ad 100%);
 padding:1.5rem 2rem;border-radius:14px;margin-bottom:1.5rem;text-align:center;
 box-shadow:0 6px 24px rgba(231,76,60,.3)}
.hero h1{color:#fff!important;font-size:2rem!important;margin:0!important;
 text-shadow:0 2px 8px rgba(0,0,0,.3)}
.hero p{color:rgba(255,255,255,.85)!important;margin:.4rem 0 0!important}
.kpi{background:linear-gradient(135deg,#1a1d23,#2c3e50);
 border:1px solid rgba(255,255,255,.08);border-radius:12px;
 padding:1.1rem;text-align:center;box-shadow:0 2px 12px rgba(0,0,0,.2)}
.kpi .n{font-size:2rem;font-weight:800;
 background:linear-gradient(135deg,#e74c3c,#f39c12);
 -webkit-background-clip:text;-webkit-text-fill-color:transparent}
.kpi .l{color:#aaa;font-size:.85rem}
.sec{border-left:4px solid #e74c3c;padding-left:12px;
 margin:2rem 0 1rem;font-size:1.25rem;font-weight:700}
@media(max-width:768px){.hero h1{font-size:1.3rem!important}.kpi .n{font-size:1.4rem}}
</style>
""", unsafe_allow_html=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ©Ÿç¨®ã‚¹ãƒšãƒƒã‚¯ (å…¨8æ©Ÿç¨®)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SPECS = {
    "ã‚¢ã‚¤ãƒ ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼": {
        1:[273.1,439.8],2:[269.7,399.6],3:[269.7,331.0],
        4:[259.0,315.1],5:[259.0,255.0],6:[255.0,255.0],
    },
    "ãƒ•ã‚¡ãƒ³ã‚­ãƒ¼ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼": {
        1:[268.6,439.8],2:[264.3,399.6],3:[260.1,331.0],
        4:[249.2,291.3],5:[240.9,257.0],6:[237.4,237.4],
    },
    "ãƒã‚¤ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼": {
        1:[273.1,439.8],2:[269.7,399.6],3:[269.7,331.0],
        4:[259.0,315.1],5:[259.0,255.0],6:[240.9,204.8],
    },
    "ãƒãƒƒãƒ”ãƒ¼ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼": {
        1:[273.1,439.8],2:[269.7,399.6],3:[269.7,331.0],
        4:[259.0,315.1],5:[259.0,255.0],6:[240.9,240.9],
    },
    "ã‚´ãƒ¼ã‚´ãƒ¼ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼": {
        1:[268.6,374.5],2:[267.5,354.2],3:[260.1,331.0],
        4:[249.2,291.3],5:[240.9,257.0],6:[237.4,237.4],
    },
    "ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼ã‚¬ãƒ¼ãƒ«ã‚º": {
        1:[268.6,374.5],2:[267.5,354.2],3:[260.1,331.0],
        4:[249.2,291.3],5:[240.9,257.0],6:[237.4,237.4],
    },
    "ãƒŸã‚¹ã‚¿ãƒ¼ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼": {
        1:[268.6,374.5],2:[267.5,354.2],3:[260.1,331.0],
        4:[249.2,291.3],5:[240.9,257.0],6:[237.4,237.4],
    },
    "ã‚¦ãƒ«ãƒˆãƒ©ãƒŸãƒ©ã‚¯ãƒ«": {
        1:[267.5,425.6],2:[261.1,402.1],3:[256.0,350.5],
        4:[242.7,322.8],5:[233.2,297.9],6:[216.3,277.7],
    },
}
_DEF = SPECS["ãƒã‚¤ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼"]

def _probs(model, s):
    spec = _DEF
    for k in SPECS:
        if k in model: spec = SPECS[k]; break
    d = spec.get(s, spec[1])
    return 1/d[0], 1/d[1]

def _model(url):
    try:
        qs = parse_qs(urlparse(url).query)
        if "kishu" in qs: return unquote(qs["kishu"][0])
    except Exception: pass
    return "ãƒã‚¤ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼V"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å…¥åŠ›ãƒ‘ãƒ¼ã‚µãƒ¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def parse_input(text):
    text = text.strip().strip('"').strip("'")
    out = []
    for ln in text.split("\n"):
        ln = ln.strip().strip('"').strip("'")
        if not ln or ln.startswith("#"): continue
        parts = ln.split(",", 1)
        if len(parts) == 2 and parts[1].strip():
            out.append((parts[0].strip(), parts[1].strip()))
    return out

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° (requestsç‰ˆ â€” Chromeä¸è¦!)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                  "AppleWebKit/537.36 (KHTML, like Gecko) "
                  "Chrome/120.0.0.0 Safari/537.36"
}

def scrape(date_label, url):
    model = _model(url)
    try:
        r = requests.get(url, headers=_HEADERS, timeout=20)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")

        tbl = None
        for t in soup.find_all("table"):
            txt = t.text
            if "BB" in txt and "RB" in txt and "å°ç•ª" in txt:
                tbl = t; break
        if not tbl:
            return [], "ãƒ†ãƒ¼ãƒ–ãƒ«æœªæ¤œå‡º"

        rows = tbl.find_all("tr")
        hdr = [c.text.strip() for c in rows[0].find_all(["th","td"])]

        try:
            hm = {
                "id":   next(i for i,s in enumerate(hdr) if "å°ç•ª" in s),
                "spin": next(i for i,s in enumerate(hdr) if "Gæ•°" in s),
                "bb":   next(i for i,s in enumerate(hdr) if s == "BB"),
                "rb":   next(i for i,s in enumerate(hdr) if s == "RB"),
            }
        except StopIteration:
            return [], f"ã‚«ãƒ©ãƒ æœªæ¤œå‡º (ãƒ˜ãƒƒãƒ€ãƒ¼: {hdr})"

        data = []
        for row in rows[1:]:
            cs = [c.text.strip().replace(",","") for c in row.find_all(["th","td"])]
            if len(cs) <= max(hm.values()): continue
            sp = cs[hm["spin"]]
            if not sp.isdigit(): continue
            spin = int(sp)
            if spin == 0: continue
            data.append(dict(
                date=date_label, machine_id=cs[hm["id"]], model=model,
                spin=spin,
                bb=int(cs[hm["bb"]]) if cs[hm["bb"]].isdigit() else 0,
                rb=int(cs[hm["rb"]]) if cs[hm["rb"]].isdigit() else 0,
            ))
        return data, None
    except requests.RequestException as e:
        return [], f"é€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}"
    except Exception as e:
        return [], str(e)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# è¨­å®šæ¨å®š
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def estimate(data):
    for item in data:
        total, likes = 0, {}
        for s in range(1, 7):
            pb, pr = _probs(item["model"], s)
            lk = binom.pmf(item["bb"], item["spin"], pb) \
               * binom.pmf(item["rb"], item["spin"], pr)
            likes[s] = lk; total += lk
        for s in range(1, 7):
            item[f"p{s}"] = likes[s]/total if total > 0 else 0
        item["hi"] = item["p5"] + item["p6"]
        item["est"] = max(range(1, 7), key=lambda s: item[f"p{s}"])
    return data

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ã‚°ãƒ©ãƒ•
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def fig_matsubi(df):
    st.markdown('<div class="sec">ğŸ“ æœ«å°¾åˆ†æ</div>', unsafe_allow_html=True)
    g = df.groupby("end_digit")["hi"].mean().reset_index()
    g.columns = ["æœ«å°¾","é«˜è¨­å®šæœŸå¾…åº¦"]
    fig, ax = plt.subplots(figsize=(10,5))
    colors = ["#e74c3c" if v>.3 else "#3498db" for v in g["é«˜è¨­å®šæœŸå¾…åº¦"]]
    sns.barplot(x="æœ«å°¾", y="é«˜è¨­å®šæœŸå¾…åº¦", data=g, palette=colors, ax=ax)
    ax.set_title("å°ç•ªå·æœ«å°¾ã”ã¨ã®é«˜è¨­å®šæœŸå¾…åº¦", fontsize=14, fontweight="bold")
    ax.axhline(.3, color="gray", ls="--", alpha=.5, label="åŸºæº–ãƒ©ã‚¤ãƒ³")
    ax.legend(); ax.grid(axis="y", alpha=.3); fig.tight_layout()
    st.pyplot(fig); plt.close(fig)
    top = g.sort_values("é«˜è¨­å®šæœŸå¾…åº¦", ascending=False).head(3)
    cols = st.columns(3)
    medals = ["ğŸ¥‡","ğŸ¥ˆ","ğŸ¥‰"]
    for i, (_, r) in enumerate(top.iterrows()):
        cols[i].metric(f"{medals[i]} æœ«å°¾{int(r['æœ«å°¾'])}", f"{r['é«˜è¨­å®šæœŸå¾…åº¦']:.3f}")

def fig_cluster(df):
    st.markdown('<div class="sec">ğŸ”— ä¸¦ã³ãƒ»å¡Šåˆ†æ</div>', unsafe_allow_html=True)
    g = df.groupby("mid")["hi"].mean().reset_index()
    g.columns = ["å°ç•ªå·","é«˜è¨­å®šæœŸå¾…åº¦"]
    fig, ax = plt.subplots(figsize=(14,5))
    sns.scatterplot(x="å°ç•ªå·", y="é«˜è¨­å®šæœŸå¾…åº¦", data=g, s=100,
                    color="#e74c3c", alpha=.7, zorder=5, ax=ax)
    ax.plot(g["å°ç•ªå·"], g["é«˜è¨­å®šæœŸå¾…åº¦"], color="#3498db", alpha=.4, lw=2)
    ax.set_title("å°ç•ªå·é †ã®é«˜è¨­å®šæœŸå¾…åº¦", fontsize=14, fontweight="bold")
    ax.grid(axis="y", ls="--", alpha=.5); plt.xticks(rotation=45)
    fig.tight_layout(); st.pyplot(fig); plt.close(fig)
    hot = g[g["é«˜è¨­å®šæœŸå¾…åº¦"] > .4]
    if len(hot):
        st.success(f"ğŸ¯ é«˜è¨­å®šãŒæœŸå¾…ã§ãã‚‹å°: {len(hot)} å°")
        st.dataframe(hot.style.format({"é«˜è¨­å®šæœŸå¾…åº¦":"{:.3f}"}), use_container_width=True)

def fig_corner(df):
    st.markdown('<div class="sec">ğŸ¢ è§’å° ï¼‹ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—</div>', unsafe_allow_html=True)
    uids = sorted(df["mid"].unique())
    islands, tmp = [], []
    for i, m in enumerate(uids):
        if i > 0 and m - uids[i-1] > 5:
            if tmp: islands.append(tmp)
            tmp = []
        tmp.append(m)
    if tmp: islands.append(tmp)
    st.info(f"æ¤œå‡ºã•ã‚ŒãŸå³¶: **{len(islands)}**")
    ms = df.groupby("mid")["hi"].mean()
    ld = []
    for isl in islands:
        corners = {isl[0], isl[-1]}
        for m in isl:
            if m in ms:
                ld.append(dict(id=m, type="è§’å°" if m in corners else "ä¸­å¤®å°", score=ms[m]))
    if not ld: return
    ldf = pd.DataFrame(ld)

    fig, ax = plt.subplots(figsize=(8,5))
    sns.boxplot(x="type", y="score", data=ldf, palette="Set2",
                hue="type", legend=False, ax=ax)
    ax.set_title("è§’å° vs ä¸­å¤®å°", fontsize=14, fontweight="bold")
    ax.set_ylabel("é«˜è¨­å®šæœŸå¾…åº¦"); ax.grid(axis="y", alpha=.3)
    fig.tight_layout(); st.pyplot(fig); plt.close(fig)

    sm = ldf.groupby("type")["score"].agg(["mean","median","std","count"])
    sm.columns = ["å¹³å‡","ä¸­å¤®å€¤","æ¨™æº–åå·®","å°æ•°"]
    st.dataframe(sm.style.format({"å¹³å‡":"{:.3f}","ä¸­å¤®å€¤":"{:.3f}","æ¨™æº–åå·®":"{:.3f}"}),
                 use_container_width=True)

    mx = max(len(isl) for isl in islands)
    grid = np.full((len(islands), mx), np.nan)
    ann  = np.full((len(islands), mx), "", dtype=object)
    for r, isl in enumerate(islands):
        for c, m in enumerate(isl):
            if m in ms: grid[r,c] = ms[m]; ann[r,c] = str(m)
    fig, ax = plt.subplots(figsize=(12, max(4, len(islands)*1.2)))
    sns.heatmap(grid, annot=ann, fmt="", cmap="YlOrRd",
                cbar_kws={"label":"é«˜è¨­å®šæœŸå¾…åº¦"}, linewidths=.5, ax=ax)
    ax.set_title("ãƒ›ãƒ¼ãƒ«é…ç½®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—", fontsize=14, fontweight="bold")
    ax.set_xlabel("å³¶å†…ã®ä½ç½®"); ax.set_ylabel("å³¶ç•ªå·")
    fig.tight_layout(); st.pyplot(fig); plt.close(fig)

def fig_overall(df):
    st.markdown('<div class="sec">ğŸ² å…¨å°ç³»ãƒ»è¨­å®šåˆ†å¸ƒ</div>', unsafe_allow_html=True)
    da = df.groupby("date")["est"].mean().reset_index()
    da.columns = ["æ—¥ä»˜","å¹³å‡æ¨å®šè¨­å®š"]
    st.dataframe(da.style.format({"å¹³å‡æ¨å®šè¨­å®š":"{:.2f}"}), use_container_width=True)
    fig, ax = plt.subplots(figsize=(8,5))
    sc = df["est"].value_counts().sort_index()
    sns.barplot(x=sc.index, y=sc.values, palette="viridis", ax=ax)
    ax.set_title("æ¨å®šè¨­å®šã®åˆ†å¸ƒ", fontsize=14, fontweight="bold")
    ax.set_xlabel("æ¨å®šè¨­å®š"); ax.set_ylabel("å°æ•°")
    ax.grid(axis="y", alpha=.3)
    for i, v in enumerate(sc.values): ax.text(i, v+.5, str(v), ha="center", fontweight="bold")
    fig.tight_layout(); st.pyplot(fig); plt.close(fig)
    ratio = len(df[df["est"] >= 5]) / len(df) * 100
    if ratio > 30:   st.success(f"âœ¨ é«˜è¨­å®šæ¯”ç‡: **{ratio:.1f}%** â€” å¤šã‚ã§ã™ï¼")
    elif ratio > 15: st.info(f"ğŸ‘ é«˜è¨­å®šæ¯”ç‡: **{ratio:.1f}%** â€” æ¨™æº–çš„")
    else:            st.warning(f"âš ï¸ é«˜è¨­å®šæ¯”ç‡: **{ratio:.1f}%** â€” å°‘ãªã‚")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ã‚µã‚¤ãƒ‰ãƒãƒ¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with st.sidebar:
    st.markdown("## ğŸ“ ãƒ‡ãƒ¼ã‚¿å…¥åŠ›")
    st.caption("ã€Œæ—¥ä»˜, URLã€ã‚’1è¡Œãšã¤å…¥åŠ›")
    input_text = st.text_area(
        "å…¥åŠ›ãƒ‡ãƒ¼ã‚¿",
        placeholder="2/7, https://min-repo.com/xxxxx\n2/14, https://min-repo.com/yyyyy",
        height=200)
    run = st.button("ğŸš€ åˆ†æé–‹å§‹", use_container_width=True, type="primary")
    st.markdown("---")
    st.markdown("**å…¥åŠ›å½¢å¼:** `æ—¥ä»˜, URL`")
    with st.expander("ğŸ“‹ å¯¾å¿œæ©Ÿç¨®ä¸€è¦§ (å…¨8æ©Ÿç¨®)"):
        st.markdown("""
- Sã‚¢ã‚¤ãƒ ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼EX
- Sãƒ•ã‚¡ãƒ³ã‚­ãƒ¼ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼2
- Sãƒã‚¤ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼V
- Sãƒãƒƒãƒ”ãƒ¼ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼V3
- Sã‚´ãƒ¼ã‚´ãƒ¼ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼3
- Sã‚¸ãƒ£ã‚°ãƒ©ãƒ¼ã‚¬ãƒ¼ãƒ«ã‚ºSS
- SãƒŸã‚¹ã‚¿ãƒ¼ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼
- Sã‚¦ãƒ«ãƒˆãƒ©ãƒŸãƒ©ã‚¯ãƒ«ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼
        """)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒ˜ãƒƒãƒ€ãƒ¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.markdown("""
<div class="hero">
    <h1>ğŸ° ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼ ãƒ›ãƒ¼ãƒ«å‚¾å‘åˆ†æãƒ„ãƒ¼ãƒ«</h1>
    <p>URLã‚’å…¥åŠ› â†’ã€Œåˆ†æé–‹å§‹ã€â†’ æœ«å°¾ãƒ»ä¸¦ã³ãƒ»ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’è‡ªå‹•åˆ†æ</p>
</div>
""", unsafe_allow_html=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if run:
    targets = parse_input(input_text)
    if not targets:
        st.error("âŒ ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚å½¢å¼: `æ—¥ä»˜, URL`")
        st.stop()

    st.info(f"ğŸ“Š {len(targets)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™")
    bar = st.progress(0)
    status = st.empty()
    all_data, errs = [], []

    for i, (dt, url) in enumerate(targets):
        status.markdown(f"ğŸš€ **[{i+1}/{len(targets)}]** `{dt}` ã‚’å–å¾—ä¸­...")
        bar.progress(i / len(targets))
        data, err = scrape(dt, url)
        if err:
            errs.append(f"[{dt}] {err}")
            st.warning(f"âš ï¸ [{dt}] {err}")
        else:
            all_data.extend(data)
            st.success(f"âœ… [{dt}] {len(data)} å°")

    bar.progress(1.0)
    status.empty()

    if not all_data:
        st.error("âŒ ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        if errs:
            with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                for e in errs: st.code(e)
        st.stop()

    # è¨­å®šæ¨å®š + ãƒ‡ãƒ¼ã‚¿åŠ å·¥
    with st.spinner("ğŸ“Š è¨­å®šæ¨å®šä¸­..."):
        all_data = estimate(all_data)
        df = pd.DataFrame(all_data)
        df["machine_id"] = df["machine_id"].astype(str)
        df = df[df["machine_id"].str.replace("-","").str.isnumeric()].copy()
        df["mid"] = df["machine_id"].str.replace("-","").astype(int)
        df["end_digit"] = df["machine_id"].str[-1].astype(int)

    # KPIã‚«ãƒ¼ãƒ‰
    hi = len(df[df["est"] >= 5]) / len(df) * 100 if len(df) else 0
    avg = df["est"].mean() if len(df) else 0
    c1, c2, c3, c4 = st.columns(4)
    for col, n, l in [(c1,str(len(df)),"åˆ†æå°æ•°"),(c2,str(len(targets)),"å–å¾—æ—¥æ•°"),
                       (c3,f"{avg:.1f}","å¹³å‡æ¨å®šè¨­å®š"),(c4,f"{hi:.0f}%","é«˜è¨­å®šæ¯”ç‡")]:
        col.markdown(f'<div class="kpi"><div class="n">{n}</div><div class="l">{l}</div></div>',
                     unsafe_allow_html=True)
    st.markdown("<br>", unsafe_allow_html=True)

    # ã‚¿ãƒ–
    t1,t2,t3,t4,t5 = st.tabs(["ğŸ“ æœ«å°¾","ğŸ”— ä¸¦ã³","ğŸ¢ è§’å°ãƒ»ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—","ğŸ² å…¨å°ç³»","ğŸ“‹ ãƒ‡ãƒ¼ã‚¿"])
    with t1: fig_matsubi(df)
    with t2: fig_cluster(df)
    with t3: fig_corner(df)
    with t4: fig_overall(df)
    with t5:
        show = {c: {"date":"æ—¥ä»˜","machine_id":"å°ç•ªå·","model":"æ©Ÿç¨®","spin":"Gæ•°",
                     "bb":"BB","rb":"RB","est":"æ¨å®šè¨­å®š","hi":"é«˜è¨­å®šæœŸå¾…åº¦"}.get(c,c)
                for c in ["date","machine_id","model","spin","bb","rb","est","hi"]
                if c in df.columns}
        st.dataframe(df[list(show.keys())].rename(columns=show), use_container_width=True, height=500)

    csv = df.to_csv(index=False, encoding="utf-8-sig")
    st.download_button("ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv,
                       file_name=f"analysis_{datetime.now():%Y%m%d_%H%M}.csv",
                       mime="text/csv", use_container_width=True)
else:
    st.markdown("""
    ### ğŸ‘ˆ å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†
    1. **æ—¥ä»˜ã¨URLã‚’å…¥åŠ›**
    2. **ã€ŒğŸš€ åˆ†æé–‹å§‹ã€** ã‚’ã‚¯ãƒªãƒƒã‚¯
    3. çµæœãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™

    ---
    #### ğŸ’¡ å…¥åŠ›ä¾‹
    ```
    2/7, https://min-repo.com/2906014/?kishu=ãƒã‚¤ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼V
    2/14, https://min-repo.com/2921029/?kishu=ãƒã‚¤ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼V
    ```
    | åˆ†æ | å†…å®¹ |
    |------|------|
    | ğŸ“ æœ«å°¾ | æœ«å°¾(0-9)ã”ã¨ã®é«˜è¨­å®šæœŸå¾…åº¦ |
    | ğŸ”— ä¸¦ã³ | å°ç•ªå·é †ã®é«˜è¨­å®šã®åã‚Š |
    | ğŸ¢ è§’å° | è§’å°vsä¸­å¤®å° + ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— |
    | ğŸ² å…¨å°ç³» | è¨­å®šåˆ†å¸ƒãƒ»é«˜è¨­å®šæ¯”ç‡ |
    """)
